{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10646753,"sourceType":"datasetVersion","datasetId":6592228}],"dockerImageVersionId":30839,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout  # Add Dropout here\nfrom sklearn.model_selection import train_test_split\nimport glob\n\n# Paths\nreal_json_path = \"/kaggle/input/deepfake/DATASET/real_cifake_preds.json\"\nfake_json_path = \"/kaggle/input/deepfake/DATASET/fake_cifake_preds.json\"\nreal_image_dir = \"/kaggle/input/deepfake/DATASET/real_cifake_images\"\nfake_image_dir = \"/kaggle/input/deepfake/DATASET/fake_cifake_images\"\n\n# Load labels from JSON\ndef load_labels(json_path, label_value):\n    with open(json_path, \"r\") as f:\n        data = json.load(f)\n    # Create a list of labels based on index in the json file\n    labels = [label_value for _ in data]\n    return labels\n\n# Real images are labeled as 0 (real)\nreal_labels = load_labels(real_json_path, 0)\n\n# Fake images are labeled as 1 (fake)\nfake_labels = load_labels(fake_json_path, 1)\n\n\ndef load_images(image_dir, labels):\n    image_paths = sorted(glob.glob(os.path.join(image_dir, \"*.png\"))) \n    images = []\n    image_labels = []\n    for i, img_path in enumerate(image_paths):\n        img = load_img(img_path, target_size=(128, 128))  \n        img_array = img_to_array(img) / 255.0  \n        images.append(img_array)\n        image_labels.append(labels[i])  \n    return np.array(images), np.array(image_labels)\n\n\nreal_images, real_labels = load_images(real_image_dir, real_labels)\nfake_images, fake_labels = load_images(fake_image_dir, fake_labels)\n\n\n# combine the datasets\nX = np.concatenate((real_images, fake_images), axis=0)\ny = np.concatenate((real_labels, fake_labels), axis=0) \n\n# for initial testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T04:26:37.670706Z","iopub.execute_input":"2025-02-05T04:26:37.671061Z","iopub.status.idle":"2025-02-05T04:26:42.195870Z","shell.execute_reply.started":"2025-02-05T04:26:37.671025Z","shell.execute_reply":"2025-02-05T04:26:42.195181Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"Configuration 3. More complex and power model","metadata":{}},{"cell_type":"code","source":"# Build CNN Model with more layers and powerful configuration\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n    MaxPooling2D(2, 2),\n    \n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    \n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    \n    Conv2D(256, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    \n    Conv2D(512, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    \n    Flatten(),\n    \n    Dense(512, activation='relu'),\n    Dropout(0.5),  # Dropout for regularization\n    \n    Dense(256, activation='relu'),\n    Dropout(0.5),  \n    \n    Dense(128, activation='relu'),\n    Dropout(0.5),  \n    \n    Dense(1, activation='sigmoid')  # bin classification real or fake\n])\n\n# Compile Model with adjusted parameters\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),  # Lower learning rate for stability in learning\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Train Model\nhistory = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\ntrain_accuracy = history.history['accuracy'][-1]\nprint(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n\n\n#evaluate the accuracy on the test part of the training dataset i.e 20 percent\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f\"Test Accuracy: {accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T05:02:20.680942Z","iopub.execute_input":"2025-02-05T05:02:20.681266Z","iopub.status.idle":"2025-02-05T05:02:42.963692Z","shell.execute_reply.started":"2025-02-05T05:02:20.681245Z","shell.execute_reply":"2025-02-05T05:02:42.962915Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.4951 - loss: 0.6913 - val_accuracy: 0.4975 - val_loss: 0.6805\nEpoch 2/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5296 - loss: 0.6646 - val_accuracy: 0.7175 - val_loss: 0.5771\nEpoch 3/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7250 - loss: 0.5778 - val_accuracy: 0.7575 - val_loss: 0.5094\nEpoch 4/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7613 - loss: 0.5009 - val_accuracy: 0.7700 - val_loss: 0.4847\nEpoch 5/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7857 - loss: 0.4882 - val_accuracy: 0.7725 - val_loss: 0.4676\nEpoch 6/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7913 - loss: 0.4633 - val_accuracy: 0.7750 - val_loss: 0.4791\nEpoch 7/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7972 - loss: 0.4638 - val_accuracy: 0.7600 - val_loss: 0.5156\nEpoch 8/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8092 - loss: 0.4612 - val_accuracy: 0.7675 - val_loss: 0.4623\nEpoch 9/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8137 - loss: 0.4229 - val_accuracy: 0.7925 - val_loss: 0.4293\nEpoch 10/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8314 - loss: 0.4050 - val_accuracy: 0.7875 - val_loss: 0.4327\nEpoch 11/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8352 - loss: 0.3955 - val_accuracy: 0.8025 - val_loss: 0.4165\nEpoch 12/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8087 - loss: 0.4304 - val_accuracy: 0.7950 - val_loss: 0.4435\nEpoch 13/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8484 - loss: 0.3515 - val_accuracy: 0.8175 - val_loss: 0.4027\nEpoch 14/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8648 - loss: 0.3722 - val_accuracy: 0.8175 - val_loss: 0.3963\nEpoch 15/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8513 - loss: 0.3587 - val_accuracy: 0.8075 - val_loss: 0.3990\nEpoch 16/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8257 - loss: 0.3795 - val_accuracy: 0.8300 - val_loss: 0.3801\nEpoch 17/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8769 - loss: 0.3102 - val_accuracy: 0.8325 - val_loss: 0.3641\nEpoch 18/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8935 - loss: 0.2836 - val_accuracy: 0.8550 - val_loss: 0.3446\nEpoch 19/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8911 - loss: 0.2790 - val_accuracy: 0.8375 - val_loss: 0.3809\nEpoch 20/20\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8840 - loss: 0.3033 - val_accuracy: 0.8450 - val_loss: 0.3757\nTraining Accuracy: 86.44%\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8370 - loss: 0.3950\nTest Accuracy: 0.8450\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"saving the 80 train","metadata":{}},{"cell_type":"code","source":"# Save the trained model\nmodel.save(\"/kaggle/working/model.train80.keras\")\nprint(\"Model saved successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T04:39:35.493780Z","iopub.execute_input":"2025-02-05T04:39:35.494092Z","iopub.status.idle":"2025-02-05T04:39:35.625396Z","shell.execute_reply.started":"2025-02-05T04:39:35.494068Z","shell.execute_reply":"2025-02-05T04:39:35.624545Z"}},"outputs":[{"name":"stdout","text":"Model saved successfully.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"**TRAINING ON THE ENTIRE DATASET NO SPLIT**","metadata":{}},{"cell_type":"code","source":"# Train Model on full dataset leaving no part for testing as testing is already done in 20 percent of training data prior\nhistory = model.fit(X, y, epochs=20, batch_size=32)\n\ntrain_accuracy = history.history['accuracy'][-1]\nprint(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T04:27:39.780002Z","iopub.status.idle":"2025-02-05T04:27:39.780271Z","shell.execute_reply":"2025-02-05T04:27:39.780165Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Save the model","metadata":{}},{"cell_type":"code","source":"# Save the trained model\nmodel.save(\"/kaggle/working/model.fullTrain.keras\")\nprint(\"Model saved successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T04:37:00.946549Z","iopub.execute_input":"2025-02-05T04:37:00.946846Z","iopub.status.idle":"2025-02-05T04:37:01.107393Z","shell.execute_reply.started":"2025-02-05T04:37:00.946822Z","shell.execute_reply":"2025-02-05T04:37:01.106573Z"}},"outputs":[{"name":"stdout","text":"Model saved successfully.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"Saving the output","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport glob\nfrom keras.models import load_model\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# dataset path\ntest_image_dir = \"/kaggle/input/deepfake/DATASET/test\"\n\n# Load the test images\ndef load_test_images(image_dir):\n    image_paths = sorted(glob.glob(os.path.join(image_dir, \"*.png\")))  #png is assumed\n    images = []\n    filenames = []\n    for img_path in image_paths:\n        img = load_img(img_path, target_size=(128, 128))  # Resize\n        img_array = img_to_array(img) / 255.0  # Normalize\n        images.append(img_array)\n        filenames.append(os.path.basename(img_path))  # Store filenames\n    return np.array(images), filenames\n\n\ntest_images, filenames = load_test_images(test_image_dir)\n\n# load the saved model\nmodel = load_model(\"/kaggle/working/model.fullTrain.keras\")\n\n\npredictions = model.predict(test_images)\npredictions = (predictions > 0.5).astype(int)  # Convert probabilities to 0 (real) or 1 (fake)\n\n# store in json\noutput = []\nfor i, pred in enumerate(predictions):\n    output.append({\"index\": i + 1, \"prediction\": \"fake\" if pred == 1 else \"real\"})\n\n# Save to json file\noutput_json_path = \"predictions.json\"\nwith open(output_json_path, \"w\") as f:\n    json.dump(output, f, indent=4)\n\nprint(f\"Predictions saved to {output_json_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T04:38:38.644444Z","iopub.execute_input":"2025-02-05T04:38:38.644735Z","iopub.status.idle":"2025-02-05T04:38:40.426073Z","shell.execute_reply.started":"2025-02-05T04:38:38.644713Z","shell.execute_reply":"2025-02-05T04:38:40.425193Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\nPredictions saved to predictions.json\n","output_type":"stream"}],"execution_count":17}]}